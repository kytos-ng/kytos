:EP: 39
:Title: Exporting Kytos events
:Authors:
    - Austin Uwate <auwate AT fiu DOT edu>
:Created: 2025-02-12
:Status: Draft
:Type: Standard

****************************************
EP039 - Kafka NApp Proposal
****************************************


Abstract
========

This blueprint, EP 039, seeks to outline the requirements, features, and implementation of a NApp designed for exporting Kytos events to external applications. Without this NApp, external applications must to interact with Kytos APIs and log entries to obtain the network state, which leads to traffic engineering delays and extra load for Kytos to manage. By pushing data to an event broker, external application can consume data in real time without any impacts to Kytos. 


Motivation
==========

- As Kytos grows and the number of external applications consuming data from Kytos's API increases, maintaining a high-performance system becomes critical. Relying on constant API requests and synchronous data retrieval can overwhelm the application, causing performance degradation. By pushing events to Kafka, external applications can receive the data asynchronously, which reduces the load on Kytos, improves its scalability, and ensures that the system remains fault-tolerant.
- In case of a critical error or debugging cycle, engineers need consistent and reliable logging. By leveraging a lightweight data producer via Kafka, engineers can see exactly what happens in real-time.


Rationale
=========

The implementation took a simple, object-oriented approach in development. Certain architectural decisions were made and the following sections discuss the motives behind them:

- **Kafka for High-Volume Event Exporting**
  
  - Kafka was selected due to its high throughput, durability, and fault-tolerant architecture, making it well-suited for exporting large volumes of events quickly and reliably.
    - Kafka is already leveraged by other projects within the AmLight consortium, which allows us to build on existing infrastructure and expertise, reducing operational overhead and increasing interoperability.
  - Unlike RabbitMQ, which is optimized for low-latency message delivery and supports complex routing, Kafka excels in handling large-scale streaming data with horizontal scalability and log-based persistence.
  - Kafka enables better replay and auditing capabilities, as consumers can re-read streams at will, which is particularly valuable for debugging or downstream processing.

- **Asynchronous Architecture for the NApp**

  - Kytos is progressively evolving toward an asynchronous architecture for its NApps to better handle I/O-bound operations and network events, aligning with modern event-driven design.
  - An async-dominant approach improves throughput by allowing the NApp to process multiple tasks concurrently without being blocked by synchronous waits or thread contention.
  - Async code uses cooperative multitasking, which typically consumes less memory than thread-based concurrency models, resulting in improved performance under high load.
  - This design choice enhances the NApp's scalability and responsiveness, particularly when interacting with external services like Kafka or device APIs, which benefit from non-blocking I/O operations.

- **NApp Configuration: Acknowledgements and Idempotent Producers**

  - While developing the NApp, it become necessary to specify `acks=all` in `settings.py` to ensure that a message is only considered successfully written when all in-sync replicas acknowledge receipt. This provides the strongest delivery guarantee Kafka offers.
    - This works by waiting for all replicas to confirm they received the data. It mitigates the risk of message loss significantly, even in the event of a broker failure immediately after write.
  - This setting is critical in our use case where event reliability is prioritized over latencyâ€”especially when exporting high-value or state-sensitive data.
  - Combined with Kafka's log-based persistence model, this acknowledgment strategy ensures robustness in message delivery and stream integrity.

  - To further improve reliability and fault tolerance, `enable.idempotence=true` was also enabled in the Kafka producer configuration.
  - Idempotent producers ensure that even if a message is retried due to a network error or broker issue, it will not be duplicated in the Kafka topic.
    - This is achieved by assigning sequence numbers to messages per producer session, allowing Kafka to detect and discard duplicates.
  - Enabling idempotence is especially useful in asynchronous systems where retries are common; it ensures at-least-once delivery does not turn into more-than-once, preserving data correctness and consistency in downstream consumers.

I. Requirements
===============

This blueprint has the following characteristics:

  1. - This NApp requires a reachable Kafka cluster to be fully operational.
      - For normal cluster conditions, the NApp should start up and shut down gracefully, using available async methods.
      - In the case of an unreachable cluster, this NApp should follow the following behaviors, based on when the outage occurs:
        - 1: On start-up: The NApp should retry connection, up to a limit of 3 times (with a 10 second connection timeout). If connection fails, then processed events should be dropped.
        - 2: In operation: The NApp should retry connection, up to a limit of 3 times. The NApp is designed to buffer up to 32MB (max) before it sends, so if the connection fails when the buffer is full, it should log a warning and drop the message.
          - If a message cannot be sent or appended to the bufer within that time, use tenacity's retry mechanic and async locking to retry message delivery. If the connection cannot be processed, drop the message.
        - 3: On shut-down: The NApp should retry connection, up to a limit of 3 times. The shutdown mechanic tries to close a connection and flush any remaining messages. If connection fails, then the messages should be dropped.

  2. - This NApp requires a Kafka topic to be created with suitable partitions available.
      - To reduce dependency reliance, the NApp will not rely on `kafka-python-ng` to create topics, but rather will manually do this.

II. How kafka_events works with Kytos
===============================

This section provides an in-depth explanation of how the kafka_events integrates with Kytos, detailing its workflow, event handling, and interactions with Kafka.

1. The kafka_events serves as a listener for Kytos, enabling efficient event-driven communication by filtering, processing, and forwarding network events. It ensures that only relevant events are published to Kafka topics while discarding unnecessary ones based on configuration.

- Workflow
  - Initialization
    - kafka_events starts execution through the setup() function.
    - Within setup(), an instance of KafkaSendOperations is created.
    - Within setup(), the running event loop is retrieved and used to run KafkaSendOperations' setup.
  - Event Listening and Filtering
    - kafka_events listens to all Kytos network events by subscribing to the event bus.
    - It checks each event against a predefined configuration to determine whether it should be processed.
      - Event filtering should be done using regular expressions, instead of manually inserting each name.
    - Events that are not configured for processing are filtered out and discarded.
  - Sending Data
    - In the event loop, kafka_events will serialize the JSON message, grab an asyncio Lock, then use `aiokafka` to append the message to the batch.
    - If `aiokafka` throws an exception, tenacity's retry mechanic will continuously send data until we reach `ALLOWED_RETRIES`.
  - Shutdown
    - kafka_events receives starts the shutdown() function
    - Within shutdown(), all tasks are canceled as the event loop has been stopped
    - Within shutdown(), the producer is shut down and messages should be flushed to Kafka.
  - Key Components
    - Event Listener: Listens to all Kytos events and applies filtering rules.
    - KafkaSendOperations: Handles functionality for interfacing with Kafka.


III. How kafka_events interacts with Kafka
===============================================

1. The kafka_events also serves as an asynchronous producer of events, producing serialization and network submission functionality.

- Publishing to Kafka
  - Serialization
    - Once filtered, kafka_events will add a task to be completed in the MainThread event loop.
    - Events are serialized using JSON and appended to `aiokafka's` batch to be published to the corresponding Kafka topic. This is to be completed before kafka_events is run.
      - The topic name is configured in `settings.py`.
      - The default is `event_logs`.
      - Kafka ensures these events are durably stored and available for consumption by downstream services.
  - Production
    - Events are sent in batches asynchronously, ensuring maximum efficiency in network requests and processing.
    - We rely on batching to enqueue data in the case of a cluster outage.
    - Each message is sent to the same topic, but divided into their respective partitions based on keys.
      - The amount of partitions is equal to the amount of different event types that need to be consumed.
      - The amount of partitions that can be created safely is relatively high, so short-term to medium-term concerns over scalability are covered.
        - If scalability becomes a concern, we can split topics are continue creating more partitions.
  - Key Components
    - KafkaSendOperations: Handles the Kafka functionality like event publishing.


IV. Configurations in settings.py
==============================

IV. Configurations in settings.py

1. This section describes the key configuration parameters used by the kafka_events application. These constants define how the application connects to Kafka, manages topics, handles message delivery, and filters events.

- Key Configuration Constants
  - BOOTSTRAP_SERVERS
    - Description: Specifies the Kafka server's address (hostname and port).
    - Usage: This setting is critical for establishing the connection with the Kafka broker.
  - ACKS
    - Description: Determines the level of message acknowledgements required by Kafka.
    - Available Options:
      - 0: No acknowledgements required.
      - 1: Only the leader broker must acknowledge.
      - "all": All in-sync replicas must acknowledge the message.
      - Usage: Controls the reliability and durability of message delivery.
      - Note: This may increase latency between the application during sends. To add this functionality, ensure tolerance for when the application is sending to kafka but the also wants to enqueue new requests.
  - ENABLE_ITEMPOTENCE
    - Description: Tells aiokafka to keep track of all messages
    - Requires ACKS == "all"
    - Available Options:
      - True: Enabled
      - False: Disabled
  - REQUEST_TIMEOUT_MS
    - Description: The amount of time aiokafka waits while trying to send requests to Kafka
    - Takes an integer (minimum 1)
  - ALLOWED_RETRIES
    - Description: The amount of retries that tenacity's retry mechanic will try until
    - Takes an integer (minimum 0)
  - DEFAULT_NUM_PARTITIONS
    - Description: Sets the default number of partitions per Kafka topic.
    - Usage: Influences the parallelism and throughput of message processing.
  - IGNORED_EVENTS
    - Description: Defines a set of event names that should be filtered out and not processed.
    - Usage: Helps in ignoring events that are not relevant to the application's processing logic.
  - REPLICATION_FACTOR
    - Description: Specifies the number of times each partition is replicated across Kafka brokers.
    - Usage: Enhances data redundancy and fault tolerance.
    - Note: The value should not exceed the number of available Kafka brokers.
  - TOPIC_NAME
    - Description: The Kafka topic from which messages are sent and/or consumed.
    - Usage: Acts as the central channel for event logging and communication between components.
  - COMPRESSION_TYPE
    - Description: The type of compression applied to messages sent to Kafka.
    - Example: "gzip"
    - Usage: Reduces network load and improves performance by compressing message data.

V. `managers/``

This folder contains the relevant domain specific classes that manage data accordingly.

1. `kafka_ops.py`

- This contains the KafkaSendOperations class, which handles data serialization and transfer to `Kafka`.
- Mainly `async`, following conventions and directives from `kytos` advances in `asyncio`.
  - Uses the `aiokafka` framework instead of `kafka-python` or `kafka-python-ng`.

VI. Events
==========

  1. This section describes the how and why events are to be filtered in kafka_events

  - Filtering
    - Events are to be filtered using regular expressions (regex)
      - This allows for flexibility in rejecting some or all of a given producer's events.
    - Some events may not be necessary to downstream consumers, thus ignoring them would reduce Kafka's burden and improve throughput.


VII. Dependencies
=================

 * kytos
 * aiokafka - [0.12.0]


VIII. Kafka message structure
======================

1. Overview
------------
A Kafka message consists of **a key, value, headers, timestamp, and metadata**. The **AIOKafkaProducer** sends messages as **ProducerRecord** objects.

2. Kafka Message Format
------------------------
Each message follows this structure:

.. list-table:: Kafka Message Fields
   :widths: 20 20 60
   :header-rows: 1

   * - Field
     - Type
     - Description
   * - **Key**
     - ``bytes`` or ``None``
     - Used for partitioning. If ``None``, Kafka assigns a random partition.
   * - **Value**
     - ``bytes``
     - The actual message payload (usually JSON in our case).
   * - **Headers**
     - ``list[(str, bytes)]``
     - Optional metadata as key-value pairs.
   * - **Timestamp**
     - ``int`` (ms) or ``None``
     - Event creation time (epoch milliseconds).
   * - **Topic**
     - ``str``
     - Destination topic name.
   * - **Partition**
     - ``int`` or ``None``
     - If specified, sends the message to that partition; otherwise, Kafka decides.

3. Example Message Structure (JSON Payload)
--------------------------------------------
When ``handle_events()`` sends a Kafka message, the value is typically JSON-encoded, like this:

.. code-block:: json

    {
      "name": str,
      "content": dict,
      "timestamp": str,
      "id": str
    }

- **name** ``str`` The name of the KytosEvent being emitted.
- **content** ``dict`` The contents of the message, preserved from the original KytosEvent.
- **timestamp** ``str`` The ISO formatted (like 2025-04-15T20:49:05.196851) timestamp associated to when the KytosEvent was emitted.
- **id:** ``str`` The UUID identifier (in str format) that the KytosEvent was originally emitted with.

4. AIOKafkaProducer Example
----------------------------
How the message is sent inside the Kytos event handler:

.. code-block:: python

    await self._producer.send(
        topic="kytos_events",
        key=None,  # Kafka decides the partition
        value=json.dumps(event_data).encode(),  # Convert JSON to bytes
        headers=[("source", "kytos".encode())],  # Custom headers
        timestamp_ms=int(time.time() * 1000)  # Timestamp in ms
    )

5. How Kafka Stores the Message
--------------------------------
Kafka writes the message to a partition inside a topic. The message is stored in **binary format** with an **offset**:

.. code-block:: text

    Topic: kytos_events, Partition: 2
    --------------------------------------------------
    Offset | Key   | Value (JSON)                    | Timestamp
    --------------------------------------------------
    1023   | None  | { "event": "kytos/..." }        | 1707859200000
    1024   | None  | { "event": "kytos/..." }        | 1707859210000

6. Message Retrieval (Kafka Consumer Example)
----------------------------------------------
A consumer reads the message and decodes it:

.. code-block:: python

    async for msg in consumer:
        event = json.loads(msg.value.decode())
        print(f"Received: {event}")


IX. Implementation details ``v1``
===================================

The following requirements clarify certain details and expected behavior for ``kafka_events`` v1:

1. Initialization (setup())
  - Log the startup process: "SETUP Kytos/Kafka"
  - Create Kafka Producer and Admin Client:
  - Instantiate KafkaSendOperations, which sets up:
    - _setup_admin(): Creates a KafkaAdminClient, retrying up to 3 times if Kafka isn't available.
  - Grab MainThread event loop.
    - Retrieves the MainThread event loop for usage on KafkaSendOperations.
    - Enqueue's KafkaSendOperations' setup() function.

2. Event Handling (handle_events())
  - Triggered when a switch connects (or other event matches the regex pattern .*).
  - Check if the event needs to be filtered out; if so, ignore it.
  - Send the event data to Kafka via _send_ops.send_message()
    - Message sending is to be enqueued on the event loop.

  - send_message():
    - Converts the event to JSON.
    - Acquires an asyncio semaphore Lock to ensure sequential delivery
    - Uses AIOKafkaProducer.send() to append to the batch and later publish it to the Kafka topic.

3. Shutdown (shutdown())
  - Log the shutdown process: "SHUTDOWN Kafka/Kytos"
  - Cancel all pending async tasks. 
  - Wait for the AIOKafkaProducer's shutdown sequence to be successful.

X. Benchmarks

The following benchmarks were the product of sending 400 requests (split across 10 threads) to the `mef_eline` endpoint to create `kytos/mef_eline.created` events naturally through `kytos`.
The following benchmarks were the product of sending a request to a REST API endpoint to create 50_000 `KytosEvents` like the following:

.. code-block:: python

    KytosEvent("kytos/sample_ui.do_work", content={"value": "x" * 10_000})

EPS
---

| Implementation | Mean | Median | Standard Deviation |
|--------|--------|--------|--------|
| MainThread | 510.3469387755102 | 529.5 | 504.16585184252443 |

XI. Open Questions / Future Work
=================================

  1. Error codes
  2. Route messages to their partitions based on key usage
  3. When filtering events, use Regex patterns instead of Set.
    - Eliminates redundancy by excluding all events from particular groups, instead of listing each individually.
  4. Add endpoints that provide clients with useful data
    - Currently the endpoints have been removed as there is no use. However, this can change with future work.
  5. Use a TBD `async shutdown` method instead of the synchronous version
    - This would allow `AIOKafkaProducer` to be shut down gracefully
  6. Use a TBD `async setup` method instead of the synchronous version
    - This would allow `AIOKafkaProducer` to be awaited gracefully instead of awaiting within the event listener.
  7. If scalability becomes a concern, we can split topics are continue creating more partitions.
    - How this would work would be to logically split target events into specific topics and to add a key to each exported event so they have their own partition.
    - For example, if the amount of unique events from `flow_manager` or `mef_eline` become to big to handle on one topic, we can make a separate topic for them and continue adding partitions.\
  8. In the case of a `Kafka` outage, memory consumption could spike and cause `Kytos` to freeze if not handled properly.